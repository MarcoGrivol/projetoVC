{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d74e7669-f00d-4b5c-91ce-fb1ab5d546a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# imagens\n",
    "PATH = 'C:\\\\Users\\\\marco\\\\Google Drive\\\\ComputerScience\\\\VisÃ£o Computacional\\\\images\\\\'\n",
    "\n",
    "def getImagesFromFolder(folder_path):\n",
    "    \"\"\"\n",
    "    Retorna todas as imagens .jpg com nomes na pasta.\n",
    "    \n",
    "    Return: list(tuple(fileName, img))\n",
    "    \"\"\"\n",
    "    imgs_with_names = []\n",
    "    for file in listdir(folder_path):    \n",
    "        image_path = join(folder_path, file)\n",
    "        if isfile(image_path) and file.endswith('.jpg'):\n",
    "            # seleciona imagens .jpg\n",
    "            img = plt.imread(image_path)\n",
    "            imgs_with_names.append((file, img))\n",
    "    return imgs_with_names\n",
    "\n",
    "def SIFT(img):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "def matcher(descriptorsA, descriptorsB):\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    best_matches = bf.match(descriptorsA, descriptorsB)\n",
    "    raw_matches = sorted(best_matches, key=lambda x:x.distance)\n",
    "    return raw_matches\n",
    "\n",
    "def getHomography(kpsA, kpsB, descriptorsA, descriptorsB, matches, reprojThresh):\n",
    "    # convert the keypoints to numpy arrays\n",
    "    kpsA = np.float32([kp.pt for kp in kpsA])\n",
    "    kpsB = np.float32([kp.pt for kp in kpsB])\n",
    "    \n",
    "    if len(matches) > 4:\n",
    "\n",
    "        # construct the two sets of points\n",
    "        ptsA = np.float32([kpsA[m.queryIdx] for m in matches])\n",
    "        ptsB = np.float32([kpsB[m.trainIdx] for m in matches])\n",
    "        \n",
    "        # estimate the homography between the sets of points\n",
    "        (H, status) = cv2.findHomography(ptsA, ptsB, cv2.RANSAC, reprojThresh)\n",
    "\n",
    "        return (matches, H, status)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7ae6c8f9-b974-4f19-8558-29de01c30295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 1200, 1200)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ['0', '1']\n",
    "files = []\n",
    "for i in ids:\n",
    "    folder_path = join(PATH, i)\n",
    "    files.extend(getImagesFromFolder(folder_path))\n",
    "\n",
    "names = []\n",
    "imgs = []\n",
    "imgs_gray = []\n",
    "for name, img in files:\n",
    "    if name.find('90') != -1:\n",
    "        continue\n",
    "    names.append(int(name.split('_')[0])) # pega o id\n",
    "    imgs.append(img)\n",
    "    imgs_gray.append(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY))\n",
    "names = np.array(names)\n",
    "imgs_gray = np.array(imgs_gray)\n",
    "imgs_gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "94c1f61e-c21c-4b9c-95f1-c8327b754806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 12800)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "samples = 100\n",
    "\n",
    "descriptors = []\n",
    "for img in imgs_gray:\n",
    "    kpts, desc = SIFT(img)\n",
    "    desc_samples = desc[rng.randint(desc.shape[0], size=samples)]\n",
    "    descriptors.append(desc_samples.flatten())\n",
    "    \n",
    "X = np.array(descriptors)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cb775a86-317a-4180-9e62-11b0737b674c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]), array([1, 1, 1]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separar as imagens com erros\n",
    "idx = np.where(names == 0)[0][-1] + 1 + 3\n",
    "X_train, X_test = X[:idx, :], X[idx:, :]\n",
    "Y_train, Y_test = names[:idx], names[idx:]\n",
    "Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "26fb32f5-2f0f-44d7-8a81-540f560a13bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789f1f56-6d90-4081-a405-7b334825c6c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
